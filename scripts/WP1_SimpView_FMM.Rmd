---
title: 'WP1: Simple View - Factor Mixture Model'
output: 
  html_document:
    toc: true
    toc_float: true
    
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/analysis/") })
---

This script is used for running the factor mixture models. It will only be used *if* the CFA supports a two-factor structure, otherwise we will use a latent profile model (WP1_SimpView_LPA.Rmd).

# Set-up

```{r libraries}
# Specify packages
pkgs <- c("tidyverse", "MplusAutomation", "texreg", "DiagrammeR", "kableExtra", "ggalluvial", "scales")

# Use groundhog package to load correct package versions
# if (!require("groundhog")) install.packages("groundhog")
# groundhog.day <- "2021-03-01"
# groundhog::groundhog.library(pkgs, groundhog.day)

# Or if not using groundhog package - load currently installed package versions separately (reproducibility not guaranteed)
invisible(lapply(pkgs, library, character.only = TRUE))
```

```{r create-dir}
# Create subdirectories for storing mplus scripts, data files, and output, if do not already exist
if(dir.exists("./mplus_models/")==FALSE){dir.create("./mplus_models/")}
if(dir.exists("./mplus_models/fmm")==FALSE){dir.create("./mplus_models/fmm")} 
if(dir.exists("../output/")==FALSE){dir.create("../output/")}
if(dir.exists("../output/figures")==FALSE){dir.create("../output/figures")}
if(dir.exists("../output/tables")==FALSE){dir.create("../output/tables")}
```

Functions for processing the output are stored in a separate script.

```{r output-functions}
source("WP1_OutputFunctions.R")
```

###  Load and prepare data for Mplus

```{r load-data}
sv_data <- read.csv("../data/simulated/WP1_SimpView_sim_std_n1000_k3.csv")
#sv_data <- read.csv("../data/processed/WP1_data.csv")
```

Mplus has an 8-character limit, so may need to rename to avoid duplicates. 

```{r mplus-names}
# Check names
str_sub(names(sv_data), 1, 8)

# Rename any necessary, print new names
sv_data <- sv_data %>% 
  rename(nonwAcc = nonwordAcc)
```

Variable format problematic for mplus data conversion, change ID to factor.

```{r mplus-formatting}
sv_data <- sv_data %>% 
  mutate(id = as.factor(id))
```

# Factor Mixture Model to extract latent classes

**Aim:** to fit models of different n classes, using two different model specifications that each incorporate measurement non-invariance (Clark et al., 2013)

### Base model

Set up initial model, based on the final model from the WP1_SimpView_CFA.Rmd script. 

Options reduced to save time for now, but possibly change for actual modelling:
starts - 500 50
lrtbootstrap 50
lrtstarts 50 20 50 20
(taken from Geiser book)

```{r fmm-base}
# Specify final selected model
select_cfa_spec <- " acc by naraAcc wordAcc nonwAcc; \n comp by naraComp woldComp; \n [comp@0];\n [acc@0];"

# Create mixture model specification
model_spec <- paste0("%OVERALL% \n ", select_cfa_spec)

# Create base model
m_fmm_base <- mplusObject(
  TITLE = "Factor mixture model;",
  ANALYSIS = "estimator = mlr; type = mixture; starts = 100 20; algorithm = integration;",
  VARIABLE = "classes = c(1);",
  MODEL = model_spec,
  OUTPUT = "sampstat; stdyx; CINTERVAL; TECH1; TECH8; TECH11; TECH14;",
  PLOT = "TYPE = PLOT3;",
  usevariables = colnames(sv_data[,!names(sv_data) %in% c("id","k")]),
  rdata = sv_data)
```

Follow same class-enumeration process as set out by Masyn (2013) for LCA and LPA models. Fit two  different models - corresponding to  FMM-3 and FMM-4 in Clark et al. (2013). Use one-class model as a benchmark for evaluating mixture models. 

```{r fmm-benchmark}
m_fmm_benchmark <- update(m_fmm_base,
     TITLE = ~ "FMM Benchmark")

mplusModeler(m_fmm_benchmark, "./mplus_models/fmm/sv_fmm_mbenchmark.dat", run = TRUE)

# Extract parameters for the benchmark model
m_fmm_benchmark <- readModels(target = "./mplus_models/fmm", filefilter = "mbenchmark") %>% 
  mixtureSummaryTable(keepCols = c("Parameters", "Observations", "LL", "AIC", "BIC", "aBIC")) %>% 
  select(LL, AIC, BIC, aBIC) %>%
  pivot_longer(LL:aBIC, names_to = "statistic", values_to = "benchmark") %>% 
  mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC")))

```

### FMM Model A 

Tests different N-Class, 2 factor FMM models. Class varying item means, class invariant factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-a-diag}

grViz("
digraph SEM {

graph [layout = neato,
       overlap = false,
       outputorder = edgesfirst]

node [shape = rectangle,fontsize=20]


a [pos = '-5,7!', label = 'woldcomp']
b [pos = '-3,7!', label = 'naracomp']
c [pos = '0,7!', label = 'naraAcc']
d [pos = '2,7!', label = 'wordAcc']
e [pos = '4,7!', label = 'nonwAcc']

f [pos = '-4,5!', label = 'comp', shape = ellipse,fontsize=20]

g [pos = '2,5!', label = 'acc', shape = ellipse,fontsize=20]


h [pos = '-1,9!', label = 'C', shape = ellipse,fontsize=20]


f->a
f->b 

g->c
g->d
g->e

h->a 
h->b
h->c
h->d
h->e

}
")


#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-a-fit}
m_fmm_a <- lapply(2:6, function(k) {
  
  # Create class-level specifications
  class_spec <- "%c#1% \n comp; \n acc; \n comp with acc; \n [naraAcc wordAcc nonwAcc naraComp woldComp];"
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "% \n comp; \n acc; \n comp with acc; \n [naraAcc wordAcc nonwAcc naraComp woldComp];")
  }
  
  # Update model
  body<-update(m_fmm_base,
              MODEL = ~ . + "acc - comp; \n acc with comp;" )
  
  body <- update(m_fmm_base,
     TITLE = as.formula(sprintf("~ 'FMM Model A: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))

   mplusModeler(body, sprintf("./mplus_models/fmm/sv_fmm_a_%dclass.dat", k), run = TRUE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-a-output}
# Read in output
fmm_a_out <- readModels(target = "./mplus_models/fmm", filefilter = "sv_fmm_a")

# Check warnings
# for (model in 1:length(fmm_a_out)){
#   print(fmm_a_out[[model]]$input$title)
#   print(fmm_a_out[[model]]$warnings)
# }

# Print table 
fmm_a_summary <- fmm_enum_table(output = fmm_a_out)
fmm_a_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_a_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 2
**b) Information heuristics (diminishing gains from elbow plots):** 3 or 4
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):** 4


Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-a-candidates}
# Extract participant level data
fmm_a_rerun <- mm_extract_data(orig_mods = m_fmm_a, candidate_mods = 3:4, 
                               filepath = "./mplus_models/fmm",
                               rerun = TRUE, one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_a_rerun)

# Plot class means
plotMixtures_simpView(fmm_a_rerun)

# Inspect transitions 
extract_classes(fmm_a_rerun, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-a-selected}
fmm_a_final_nclass <- 3
fmm_a_final_m <- fmm_a_rerun[1]  
```


### FMM Model B

Tests different N-Class, 2 factor FMM models. Class varying item means, class varying factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-b-diag}
grViz("
digraph SEM {

graph [layout = neato,
       overlap = false,
       outputorder = edgesfirst]

node [shape = rectangle,fontsize=20]


a [pos = '-5,7!', label = 'woldcomp']
b [pos = '-3,7!', label = 'naracomp']
c [pos = '0,7!', label = 'naraAcc']
d [pos = '2,7!', label = 'wordAcc']
e [pos = '4,7!', label = 'nonwAcc']

f [pos = '-4,5!', label = 'comp', shape = ellipse,fontsize=20]

g [pos = '2,5!', label = 'acc', shape = ellipse,fontsize=20]


h [pos = '-1,5!', label = 'C', shape = ellipse,fontsize=20]


f->a
f->b 

g->c
g->d
g->e

h->a 
h->b
h->c
h->d
h->e

node [shape = circle,
        fixedsize = true,
        width = 0.1,
        color = white,
        fontcolor = white]

wc [pos = '-4.5,6!']
nc [pos = '-3.5,6!']
na [pos = '1,6!']
wa [pos = '2,6!']
nwa [pos = '3,6!']

h -> wc [style = dashed]
h -> nc [style = dashed]
h -> na [style = dashed]
h -> wa [style = dashed]
h -> nwa [style = dashed]
}
")


#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-b-fit}
m_fmm_b <- lapply(2:6, function(k) {
  
  # Create class-level specifications
  class_spec <- "%c#1% \n acc by naraAcc wordAcc nonwAcc; \n comp by naraComp woldComp; \n comp; \n acc; \n comp with acc; \n [naraAcc wordAcc nonwAcc naraComp woldComp];"
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "% \n acc by naraAcc wordAcc nonwAcc; \n comp by naraComp woldComp; \n comp; \n acc;\n comp with acc; \n [naraAcc wordAcc nonwAcc naraComp woldComp]; ")
  }
  
  # Update model
  body <- update(m_fmm_base,
     TITLE = as.formula(sprintf("~ 'FMM Model B: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))

   mplusModeler(body, sprintf("./mplus_models/fmm/sv_fmm_b_%dclass.dat", k), run = TRUE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-b-output}
# Read in output
fmm_b_out <- readModels(target = "./mplus_models/fmm", filefilter = "sv_fmm_b")

# Check warnings
# for (model in 1:length(fmm_b_out)){
#   print(fmm_b_out[[model]]$input$title)
#   print(fmm_b_out[[model]]$warnings)
# }

# Print table 
fmm_b_summary <- fmm_enum_table(output = fmm_b_out)
fmm_b_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_b_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 2
**b) Information heuristics (diminishing gains from elbow plots):** 3
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):** 3 or 4


Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-b-candidates}
# Extract participant level data
fmm_b_rerun <- mm_extract_data(orig_mods = m_fmm_b, candidate_mods = 3:4,
                               filepath = "./mplus_models/fmm",
                               rerun = TRUE, one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_b_rerun)

# Plot class means
plotMixtures_simpView(fmm_b_rerun)

# Inspect transitions 
extract_classes(fmm_b_rerun, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-b-selected}
fmm_b_final_nclass <- 3
fmm_b_final_m <- fmm_b_rerun[1]
```


### All FMM models: Summary output & final selection

Use the 2 best candidate models identified above to recalculate the approximate correct model probability.

```{r final-candidates}
# Select best models
best_fits <- c(fmm_a_final_m, fmm_b_final_m)

# Compare outputs 
best_summaries <- fmm_enum_table(best_fits) %>% 
  select(-c(VLMR_p, LMR_p, bLRT_p))

# Compute classification diagnostics
class_diag(best_fits)

# Plot class means
plotMixtures_simpView(best_fits)

# Inspect transitions 
extract_classes(best_fits, type = "fmm")
```

```{r fmm-all-table}
# Combine all summary tables
fmm_all_summaries <- rbind(fmm_a_summary, fmm_b_summary) 

# Extract number of classes modelled in class enumeration process
k_classes_modelled <- max(fmm_all_summaries$Classes) -1

# Specify table row for selected models for each spec
a_row <- which(grepl(fmm_a_final_nclass, fmm_a_summary$Classes))
b_row <- k_classes_modelled + which(grepl(fmm_b_final_nclass, fmm_b_summary$Classes))

# Format table, highlight class model of best fit in each specification
table_all <- fmm_all_summaries %>% 
  mutate(Specification = "") %>% 
  replace(is.na(.), "-") %>% 
  kbl(align = c("l", "c", "r", "c", "r", "r","r","r","r","r","r","r")) %>% 
  kable_classic(html_font = "Cambria") %>% 
  pack_rows(index = c("Model A" = k_classes_modelled, "Model B" = k_classes_modelled)) %>% 
  row_spec(c(a_row, b_row), bold = T) 
table_all

# Save table as pdf for later viewing
# save_kable(table_all, file = "../output/tables/SimpView_fmm_all_modelfit.pdf")
```

```{r fmm-all-elbow}
# Grouped elbow plots
fmm_all_summaries %>%
    mutate(model_spec = substr(Specification, 11, 12)) %>% 
    select(model_spec, Classes, LL, AIC,  BIC, aBIC) %>%
    pivot_longer(LL:aBIC, names_to = "statistic", values_to = "value") %>%
    mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC"))) %>% 
    ggplot(aes(x = as.factor(Classes), y = value)) +
    geom_point(aes(shape = model_spec)) +
    geom_line(aes(group = model_spec, linetype = model_spec)) +
    xlab("n classes") +
    theme_bw() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.y = element_blank()) +
    geom_hline(data = m_fmm_benchmark, aes(yintercept = benchmark), linetype = "dashed", colour = "red") +
    facet_wrap(statistic_relevel ~., scales = "free") + 
    labs(shape = "Model spec:", linetype = "Model spec:")

# save out for easier viewing
ggsave("../output/figures/SimpView_fmm_all_indices.tiff", dpi = 600, width = 7, height = 4, units = "in")
```
# Final selected model