---
title: 'WP1: Profiles of comprehension difficulty - Factor Mixture Model'
output: 
  html_document:
    toc: true
    toc_float: true
    
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/analysis/") })
---

This script is used for running the factor mixture models.

# Set-up

```{r libraries}
# Specify packages
pkgs <- c("tidyverse", "MplusAutomation", "texreg", "DiagrammeR", "kableExtra", "ggalluvial", "scales", "ggpubr")

# Use groundhog package to load correct package versions
# if (!require("groundhog")) install.packages("groundhog")
# groundhog.day <- "2021-03-01"
# groundhog::groundhog.library(pkgs, groundhog.day)

# Or if not using groundhog package - load currently installed package versions separately (reproducibility not guaranteed)
invisible(lapply(pkgs, library, character.only = TRUE))
```

```{r create-dir}
# Create subdirectories for storing mplus scripts, data files, and output, if do not already exist
if(dir.exists("./mplus_models/")==FALSE){dir.create("./mplus_models/")}
if(dir.exists("./mplus_models/fmm")==FALSE){dir.create("./mplus_models/fmm")} 
if(dir.exists("../output/")==FALSE){dir.create("../output/")}
if(dir.exists("../output/figures")==FALSE){dir.create("../output/figures")}
if(dir.exists("../output/tables")==FALSE){dir.create("../output/tables")}
```

Functions for processing the output are stored in a separate script.

```{r output-functions}
source("WP1_OutputFunctions.R")
```

###  Load and prepare data for Mplus

```{r load-data}
cp_data <- read.csv("../data/simulated/WP1_CompProf_sim_raw_n694_k3.csv")
#cp_data <- read.csv("../data/processed/WP1_data.csv")
```

Mplus has an 8-character limit, so rename relevant variables with short names for modelling. 

```{r mplus-names}
# Rename any necessary, print new names
cp_data <- cp_data %>% 
  rename(naraComp = nara_comp_raw_f9,
         naraAcc = nara_acc_raw_f9,
         wordAcc = read_word_raw_f9,
         nonwAcc = read_nonw_raw_f9,
         woldComp = wold_comp_raw_f8,
         f8age = age_m_f8,
         f9age = age_m_f9,
         f10age = age_m_f10,
         naraRate = nara_rate_raw_f9,
         woldVcb = wold_vcb_raw_f8,
         wiscVcb = wisc_vcb_raw_f8,
         wiscPcmp = wisc_pcmp_raw_f8,
         wiscCode = wisc_code_raw_f8,
         wiscParr = wisc_parr_raw_f8,
         wiscBloc = wisc_bloc_raw_f8,
         wiscObja = wisc_obja_raw_f8,
         wiscBwsp = wisc_bwsp_raw_f8,
         cntspan = cntsp_span_raw_f10,
         attnSel = teach_slct_raw_f8,
         attnDiv = teach_divd_raw_f8,
         attnOpp = teach_ctr_diff_f8,
         sdqHyp = sdq_hyp_prnt_ku) 

# Check compatibility with mplus
str_sub(names(cp_data), 1, 8)
```

Variable format problematic for mplus data conversion, change ID to factor.

```{r mplus-formatting}
cp_data <- cp_data %>%
  mutate(yp_id = as.factor(yp_id))
```

# Factor Mixture Model to extract latent classes

**Aim:** to fit models of different n classes, using two different model specifications that each incorporate measurement non-invariance (Clark et al., 2013)

### Base model

Set up initial model, based on the final model from the WP1_SimpView_CFA.Rmd script. 

Options reduced to save time for now, but possibly change for actual modelling:
starts - 500 50
lrtbootstrap 50
lrtstarts 50 20 50 20
(taken from Geiser book)

```{r}
# Age regressors
age_spec <- " 
             wordAcc nonwAcc naraAcc naraComp naraRate on f9age;
             woldComp woldVcb wiscVcb wiscPcmp wiscCode wiscParr 
             wiscBloc wiscObja wiscBwsp attnSel attnDiv attnOpp on f8age;
             cntSpan on f10age;"

# Factor specification (for overall statement)
factor_spec <- " 
                acc by nonwAcc wordAcc naraAcc; 
                comp by naraComp; woldComp 
                naraRate;
                vocab by wiscVcb woldVcb ;
                perfiq by wiscPcmp wiscCode wiscParr wiscBloc wiscObja;
                execfun by wiscBwsp cntSpan attnSel attnDiv attnOpp sdqHyp;"

# Factor specification (for class statements; remove first loading as already fixed to 1)
factor_spec_class <- " 
                acc by wordAcc naraAcc; 
                comp by woldComp;
                naraRate;
                vocab by woldVcb ;
                perfiq by wiscCode wiscParr wiscBloc wiscObja;
                execfun by cntSpan attnSel attnDiv attnOpp sdqHyp;"

# Set factor means to 0 for identifiability
factor_means <- "
                 [comp@0]; [acc@0]; [vocab@0]; [perfiq@0]; [execfun@0];"     # means at 0 ? what about naraRate? 

# Factor variances
factor_vars <- " 
                acc; comp; naraRate; vocab; perfiq; execfun;" # Not sure about naraRate here as not latent variable? 

# Factor covariances  
factor_covars <- " 
                  acc with comp; acc with naraRate; acc with vocab; 
                  acc with perfiq; acc with execfun;
                  comp with naraRate; comp with vocab; 
                  comp with perfiq; comp with execfun;
                  naraRate with vocab; naraRate with perfiq; 
                  naraRate with execfun; 
                  vocab with perfiq; vocab with execfun;
                  perfiq with execfun;"

# Means of indicator variables
ind_means <- " 
              [wordAcc nonwAcc naraAcc naraComp naraRate 
              woldComp woldVcb wiscVcb wiscPcmp wiscCode 
              wiscParr wiscBloc wiscObja wiscBwsp 
              attnSel attnDiv attnOpp cntSpan];"

# Additional covariances between indicator variables (determined by initial CFA model)
ind_covars <- " 
               cntSpan with wiscBwsp;
               naraRate with naraAcc;"        # e.g., from MIs in CFA script
```


```{r fmm-base}

# Create mixture model specification (including age regressors)
model_spec <- paste0("%OVERALL% \n ",
                     age_spec,
                     factor_spec,
                     factor_means,
                     ind_covars)      ### not sure where these go - in all models in overall statement???

# Create base model
m_fmm_base <- mplusObject(
  TITLE = "Factor mixture model;",
  ANALYSIS = "estimator = mlr; type = mixture; starts = 100 20; algorithm = integration;",
  VARIABLE = "classes = c(1);",
  MODEL = model_spec,
  OUTPUT = "sampstat; stdyx; CINTERVAL; TECH1; TECH8; TECH11; TECH14;",
  PLOT = "TYPE = PLOT3;",
  usevariables = colnames(cp_data[,!names(cp_data) %in% c("yp_id", "yp_no", "k")]),
  rdata = cp_data)
```

Follow same class-enumeration process as set out by Masyn (2013) for LCA and LPA models. Fit two  different models - corresponding to  FMM-3 and FMM-4 in Clark et al. (2013). Use one-class model as a benchmark for evaluating mixture models. 

```{r fmm-benchmark}
m_fmm_benchmark <- update(m_fmm_base,
     TITLE = ~ "FMM Benchmark")

mplusModeler(m_fmm_benchmark, "./mplus_models/fmm/cp_fmm_mbenchmark.dat", run = TRUE)

# Extract parameters for the benchmark model
m_fmm_benchmark <- readModels(target = "./mplus_models/fmm", filefilter = "mbenchmark") %>% 
  mixtureSummaryTable(keepCols = c("Parameters", "Observations", "LL", "AIC", "BIC", "aBIC")) %>% 
  select(LL, AIC, BIC, aBIC) %>%
  pivot_longer(LL:aBIC, names_to = "statistic", values_to = "benchmark") %>% 
  mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC")))

```

### FMM Model A 

Tests different N-Class, 2 factor FMM models. Class varying item means, class invariant factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-a-diag}

grViz("
digraph SEM {

graph [layout = neato,
       overlap = false,
       outputorder = edgesfirst]

node [shape = rectangle,fontsize=20]


a [pos = '-5,7!', label = 'woldcomp']
b [pos = '-3,7!', label = 'naracomp']
c [pos = '0,7!', label = 'naraAcc']
d [pos = '2,7!', label = 'wordAcc']
e [pos = '4,7!', label = 'nonwAcc']

f [pos = '-4,5!', label = 'comp', shape = ellipse,fontsize=20]

g [pos = '2,5!', label = 'acc', shape = ellipse,fontsize=20]


h [pos = '-1,9!', label = 'C', shape = ellipse,fontsize=20]


f->a
f->b 

g->c
g->d
g->e

h->a 
h->b
h->c
h->d
h->e

}
")


#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-a-fit}
m_fmm_a <- lapply(2:4, function(k) {
  
  # Update model spec 1: overall model estimates (variances and covariances)
  body<-update(m_fmm_base,
              MODEL = as.formula(sprintf("~ . + '%s %s'", factor_vars, factor_covars)))
  
  # Create class-level specifications (factor variances and covariances)
  class_spec <- paste0("%c#1%", factor_vars, factor_covars, ind_means)
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "%", factor_vars, factor_covars, ind_means)
  }
  
  # ...Update model spec 2: class estimates
  body <- update(body,
     TITLE = as.formula(sprintf("~ 'FMM Model A: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))

  # Run model
  mplusModeler(body, sprintf("./mplus_models/fmm/cp_fmm_a_%dclass.dat", k), run = FALSE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-a-output}
# Read in output
fmm_a_out <- readModels(target = "./mplus_models/fmm", filefilter = "cp_fmm_a")

# Check warnings
# for (model in 1:length(fmm_a_out)){
#   print(fmm_a_out[[model]]$input$title)
#   print(fmm_a_out[[model]]$warnings)
# }

# Print table 
fmm_a_summary <- fmm_enum_table(output = fmm_a_out)
fmm_a_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_a_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 2
**b) Information heuristics (diminishing gains from elbow plots):** 3 or 4
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):** 4

Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-a-candidates}
# Extract participant level data
fmm_a_rerun <- mm_extract_data(orig_mods = m_fmm_a, candidate_mods = 3:4, 
                               filepath = "./mplus_models/fmm", analysis_id = "cp",
                               rerun = FALSE, one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_a_rerun)

# Plot class means (use select_model if not all models ran correctly)
### Note - plot saves to output/figures/ >> open and inspect separately for proper viewing
plotMixtures_compProf(fmm_a_rerun, select_model = 2)

# Inspect transitions - not yet edited/working
# extract_classes(fmm_a_rerun, select_model = 3:4, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-a-selected}
fmm_a_final_nclass <- 3
fmm_a_final_m <- fmm_a_rerun[1]  
```


### FMM Model B

Tests different N-Class, 2 factor FMM models. Class varying item means, class varying factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-b-diag}
grViz("
digraph SEM {

graph [layout = neato,
       overlap = false,
       outputorder = edgesfirst]

node [shape = rectangle,fontsize=20]


a [pos = '-5,7!', label = 'woldcomp']
b [pos = '-3,7!', label = 'naracomp']
c [pos = '0,7!', label = 'naraAcc']
d [pos = '2,7!', label = 'wordAcc']
e [pos = '4,7!', label = 'nonwAcc']

f [pos = '-4,5!', label = 'comp', shape = ellipse,fontsize=20]

g [pos = '2,5!', label = 'acc', shape = ellipse,fontsize=20]


h [pos = '-1,5!', label = 'C', shape = ellipse,fontsize=20]


f->a
f->b 

g->c
g->d
g->e

h->a 
h->b
h->c
h->d
h->e

node [shape = circle,
        fixedsize = true,
        width = 0.1,
        color = white,
        fontcolor = white]

wc [pos = '-4.5,6!']
nc [pos = '-3.5,6!']
na [pos = '1,6!']
wa [pos = '2,6!']
nwa [pos = '3,6!']

h -> wc [style = dashed]
h -> nc [style = dashed]
h -> na [style = dashed]
h -> wa [style = dashed]
h -> nwa [style = dashed]
}
")


#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-b-fit}
m_fmm_b <- lapply(2:3, function(k) {
  
  # Create class-level specifications (factor loadings, factor variance and covariance)
  class_spec <- paste0("%c#1%", factor_spec_class, factor_vars, factor_covars, ind_means)
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "%", factor_spec_class, factor_vars, factor_covars, ind_means)
  }
  
  # Update model
  body <- update(m_fmm_base,
     TITLE = as.formula(sprintf("~ 'FMM Model B: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))
 
  # Run model
   mplusModeler(body, sprintf("./mplus_models/fmm/cp_fmm_b_%dclass.dat", k), run = TRUE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-b-output}
# Read in output
fmm_b_out <- readModels(target = "./mplus_models/fmm", filefilter = "cp_fmm_b")

# Check warnings
# for (model in 1:length(fmm_b_out)){
#   print(fmm_b_out[[model]]$input$title)
#   print(fmm_b_out[[model]]$warnings)
# }

# Print table 
fmm_b_summary <- fmm_enum_table(output = fmm_b_out)
fmm_b_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_b_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 2
**b) Information heuristics (diminishing gains from elbow plots):** 3
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):** 3 or 4


Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-b-candidates}
# Extract participant level data
fmm_b_rerun <- mm_extract_data(orig_mods = m_fmm_b, candidate_mods = 3:4,
                               filepath = "./mplus_models/fmm", analysis_id = "cp",
                               rerun = TRUE, one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_b_rerun)

# Plot class means
plotMixtures_simpView(fmm_b_rerun)

# Inspect transitions 
extract_classes(fmm_b_rerun, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-b-selected}
fmm_b_final_nclass <- 3
fmm_b_final_m <- fmm_b_rerun[1]
```


### All FMM models: Summary output & final selection

Use the 2 best candidate models identified above to recalculate the approximate correct model probability.

```{r final-candidates}
# Select best models
best_fits <- c(fmm_a_final_m, fmm_b_final_m)

# Compare outputs 
best_summaries <- fmm_enum_table(best_fits) %>% 
  select(-c(VLMR_p, LMR_p, bLRT_p))

# Compute classification diagnostics
class_diag(best_fits)

# Plot class means
plotMixtures_simpView(best_fits)

# Inspect transitions 
extract_classes(best_fits, type = "fmm")
```

```{r fmm-all-table}
# Combine all summary tables
fmm_all_summaries <- rbind(fmm_a_summary, fmm_b_summary) 

# Extract number of classes modelled in class enumeration process
k_classes_modelled <- max(fmm_all_summaries$Classes) -1

# Specify table row for selected models for each spec
a_row <- which(grepl(fmm_a_final_nclass, fmm_a_summary$Classes))
b_row <- k_classes_modelled + which(grepl(fmm_b_final_nclass, fmm_b_summary$Classes))

# Format table, highlight class model of best fit in each specification
table_all <- fmm_all_summaries %>% 
  mutate(Specification = "") %>% 
  replace(is.na(.), "-") %>% 
  kbl(align = c("l", "c", "r", "c", "r", "r","r","r","r","r","r","r")) %>% 
  kable_classic(html_font = "Cambria") %>% 
  pack_rows(index = c("Model A" = k_classes_modelled, "Model B" = k_classes_modelled)) %>% 
  row_spec(c(a_row, b_row), bold = T) 
table_all

# Save table as pdf for later viewing
# save_kable(table_all, file = "../output/tables/SimpView_fmm_all_modelfit.pdf")
```

```{r fmm-all-elbow}
# Grouped elbow plots
fmm_all_summaries %>%
    mutate(model_spec = substr(Specification, 11, 12)) %>% 
    select(model_spec, Classes, LL, AIC,  BIC, aBIC) %>%
    pivot_longer(LL:aBIC, names_to = "statistic", values_to = "value") %>%
    mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC"))) %>% 
    ggplot(aes(x = as.factor(Classes), y = value)) +
    geom_point(aes(shape = model_spec)) +
    geom_line(aes(group = model_spec, linetype = model_spec)) +
    xlab("n classes") +
    theme_bw() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.y = element_blank()) +
    geom_hline(data = m_fmm_benchmark, aes(yintercept = benchmark), linetype = "dashed", colour = "red") +
    facet_wrap(statistic_relevel ~., scales = "free") + 
    labs(shape = "Model spec:", linetype = "Model spec:")

# save out for easier viewing
ggsave("../output/figures/SimpView_fmm_all_indices.tiff", dpi = 600, width = 7, height = 4, units = "in")
```

# Final selected model