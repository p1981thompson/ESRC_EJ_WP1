---
title: 'WP1: Profiles of comprehension difficulty - Factor Mixture Model'
output: 
  html_document:
    toc: true
    toc_float: true
date: '06/05/2021' 
    
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/analysis/") })
---

This script is used for running the factor mixture models. This analysis is conducted using the group(s) with poor reading comprehension, extracted in WP1_SimpView_FinalModel.Rmd. 

# Set-up

```{r libraries}
# Specify packages
pkgs <- c("tidyverse", "MplusAutomation", "texreg", "DiagrammeR", "kableExtra", "ggalluvial", "scales", "ggpubr")

# Load packages
invisible(lapply(pkgs, library, character.only = TRUE))
```

```{r create-dir}
# Create subdirectories for storing mplus scripts, data files, and output, if do not already exist
if(dir.exists("./mplus_models/")==FALSE){dir.create("./mplus_models/")}
if(dir.exists("./mplus_models/compprof/")==FALSE){dir.create("./mplus_models/compprof/")} 
if(dir.exists("./mplus_models/compprof/fmm")==FALSE){dir.create("./mplus_models/compprof/fmm")} 
if(dir.exists("../output/")==FALSE){dir.create("../output/")}
if(dir.exists("../output/figures")==FALSE){dir.create("../output/figures")}
if(dir.exists("../output/tables")==FALSE){dir.create("../output/tables")}
```

Functions for processing the output are stored in a separate script.

```{r output-functions}
source("WP1_OutputFunctions.R")
```

###  Load and prepare data for Mplus

Read in the original data file extracted for WP1 (contains all variables) and the classes extracted from the previous analysis. Filter dataset to include only the classes of interest for this analysis (those with poor comprehension in the context of relatively good reading accuracy). 

```{r load-data}
# Load all variables
cp_data <- read.csv("../data/processed/WP1_data_all.csv") %>% 
  select(cidB3153, yp_id,
         nara_comp_raw_f9, nara_acc_raw_f9, read_word_raw_f9, read_nonw_raw_f9, wold_comp_raw_f8,
         age_m_f8, age_m_f9, age_m_f10,
         nara_rate_raw_f9,
         wold_vcb_raw_f8, wisc_vcb_raw_f8,
         wisc_pcmp_raw_f8, wisc_code_raw_f8, wisc_parr_raw_f8, wisc_bloc_raw_f8, wisc_obja_raw_f8,
         wisc_bwsp_raw_f8, cntsp_span_raw_f10,
         teach_slct_raw_f8, teach_divd_raw_f8, teach_ctr_diff_f8,
         sdq_hyp_prnt_ku) %>% 
  mutate(read_comb_raw_f9 = (read_word_raw_f9 + read_nonw_raw_f9)) %>% 
  select(- c(read_word_raw_f9, read_nonw_raw_f9))

# Load class data
class_data <- read.csv("../data/processed/WP1_data_profiles.csv")  

# Merge class data and filter for group of interest 
cp_data <- cp_data %>% 
  left_join(class_data, by = c("cidB3153",
                             "age_m_f8" = "f8age",
                             "age_m_f9" = "f9age")) %>% 
  filter(c == 1) %>% 
  mutate(yp_id = as.factor(yp_id))  # re-format as factor
```

Mplus has an 8-character limit, so rename relevant variables with short names for modelling. 

```{r mplus-names}
# Rename any necessary, print new names
cp_data <- cp_data %>% 
  rename(naraComp = nara_comp_raw_f9,
         naraAcc = nara_acc_raw_f9,
         combAcc = read_comb_raw_f9,
         woldComp = wold_comp_raw_f8,
         f8age = age_m_f8,
         f9age = age_m_f9,
         f10age = age_m_f10,
         naraRate = nara_rate_raw_f9,
         woldVcb = wold_vcb_raw_f8,
         wiscVcb = wisc_vcb_raw_f8,
         wiscPcmp = wisc_pcmp_raw_f8,
         wiscCode = wisc_code_raw_f8,
         wiscParr = wisc_parr_raw_f8,
         wiscBloc = wisc_bloc_raw_f8,
         wiscObja = wisc_obja_raw_f8,
         wiscBwsp = wisc_bwsp_raw_f8,
         cntspan = cntsp_span_raw_f10,
         attnSel = teach_slct_raw_f8,
         attnDiv = teach_divd_raw_f8,
         attnOpp = teach_ctr_diff_f8,
         sdqHyp = sdq_hyp_prnt_ku) 

# Check compatibility with mplus
str_sub(names(cp_data), 1, 8)
```


# Factor Mixture Model to extract latent classes

**Aim:** to fit models of different n classes, using two different model specifications that each incorporate measurement non-invariance (Clark et al., 2013)

### Base model

Set up initial model, based on the final model from the WP1_CompProf_CFA.Rmd script. 

```{r model-spec}
# Age regressors
age_spec <- " 
            f8age; f9age; f10age;
            acc naraComp naraRate on f9age;
            perfiq woldComp wiscBwsp attnSel attnDiv attnOpp on f8age;
            wiscVcb woldVcb on f8age;
            cntSpan on f10age;"

# Factor specification (for overall statement)
factor_spec <- " 
                acc by combAcc naraAcc naraComp; 
                combAcc with naraAcc;
                lang by woldComp naraComp wiscVcb woldVcb;
                naraRate;
                perfiq by wiscPcmp wiscCode wiscParr wiscBloc wiscObja;
                execfun by wiscBwsp cntSpan attnSel attnDiv attnOpp sdqHyp wiscCode;"

# Factor specification (for class statements; remove first loading as already fixed to 1)
factor_spec_class <- " 
                acc by naraAcc naraComp; 
                combAcc with naraAcc;
                lang by naraComp wiscVcb woldVcb;
                naraRate;
                perfiq by wiscCode wiscParr wiscBloc wiscObja;
                execfun by cntSpan attnSel attnDiv attnOpp sdqHyp wiscCode;"

# Set factor means to 0 for identifiability
factor_means <- "
                 [acc@0]; [lang@0]; [perfiq@0]; [execfun@0];"

# Factor variances
factor_vars <- " 
                acc; lang; perfiq; execfun;" 

# Factor covariances  
factor_covars <- " 
                  acc with lang; acc with naraRate; 
                  acc with perfiq; acc with execfun;
                  lang with naraRate; 
                  lang with perfiq; lang with execfun;
                  naraRate with perfiq; naraRate with execfun; 
                  perfiq with execfun;"

# Means of indicator variables
ind_means <- " 
              [combAcc naraAcc naraComp naraRate 
              woldComp woldVcb wiscVcb wiscPcmp wiscCode 
              wiscParr wiscBloc wiscObja wiscBwsp 
              attnSel attnDiv attnOpp cntSpan];"
```

*Note:* Increase starts to 2000 200 for a model if best log-likelihood value not replicated (Lubke & Luningham, 2017)

```{r fmm-base}
# Create mixture model specification (including age regressors)
model_spec <- paste0("%OVERALL% \n ",
                     age_spec,
                     factor_spec,
                     factor_means)

# Create base model
m_fmm_base <- mplusObject(
  TITLE = "Factor mixture model;",
  ANALYSIS = "estimator = mlr; type = mixture; starts = 500 50;
              processors = 4(STARTS);",
  VARIABLE = "classes = c(1);",
  MODEL = model_spec,
  OUTPUT = "TECH1; TECH8; TECH11;",
  PLOT = "TYPE = PLOT3;",
  usevariables = colnames(cp_data[,!names(cp_data) %in% c("yp_id", "cidB3153", "c", "g")]),
  rdata = cp_data)
```

Follow same class-enumeration process as set out by Masyn (2013) for LCA and LPA models. Fit two  different models - corresponding to  FMM-3 and FMM-4 in Clark et al. (2013). Use one-class model as a benchmark for evaluating mixture models. 

```{r fmm-benchmark}
m_fmm_benchmark <- update(m_fmm_base,
     TITLE = ~ "FMM Benchmark")

mplusModeler(m_fmm_benchmark, "./mplus_models/compprof/fmm/cp_fmm_mbenchmark.dat", run = TRUE)

# Extract parameters for the benchmark model
m_fmm_benchmark <- readModels(target = "./mplus_models/compprof/fmm", filefilter = "mbenchmark") %>% 
  mixtureSummaryTable(keepCols = c("Parameters", "Observations", "LL", "AIC", "BIC", "aBIC")) %>% 
  select(LL, AIC, BIC, aBIC) %>%
  pivot_longer(LL:aBIC, names_to = "statistic", values_to = "benchmark") %>% 
  mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC")))
```

### FMM Model A 

Tests different N-Class, 2 factor FMM models. Class varying item means, class invariant factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-a-diag}
grViz("
digraph SEM {
graph [layout = neato,
       overlap = true,
       outputorder = edgesfirst]
node [shape = rectangle,fontsize=16]
a [pos = '-6,6!', label = 'woldcomp']
b [pos = '-4.5,6!', label = 'naracomp']
c [pos = '-3,6!', label = 'naraAcc']
d [pos = '-1.5,6!', label = 'wordAcc']
e [pos = '0,6!', label = 'nonwAcc']
f [pos = '-5,5!', label = 'comp', shape = ellipse,fontsize=16]
g [pos = '-1.5,5!', label = 'acc', shape = ellipse,fontsize=16]
h [pos = '-1,8!', label = 'C', shape = ellipse,fontsize=20]
i [pos = '-7.5,6!', label = 'naraRate']
j [pos = '2,6!', label = 'wiscVcb']
k [pos = '3.5,6!', label = 'woldVcb']
l [pos = '3,5!', label = 'vocab', shape = ellipse,fontsize=16]
m [pos = '-3,13!', label = 'perfig', shape = ellipse,fontsize=16]
a2 [pos = '-6,11!', label = 'wiscPcmp']
b2 [pos = '-4.5,11!', label = 'wiscCode']
c2 [pos = '-3,11!', label = 'wiscParr']
d2 [pos = '-1.5,11!', label = 'wiscBloc']
e2 [pos = '0,11!', label = 'wiscObja']
n [pos = '6,13!', label = 'execfun', shape = ellipse,fontsize=16]
a3 [pos = '2,11!', label = 'wiscBwsp']
b3 [pos = '3.5,11!', label = 'cntSpan']
c3 [pos = '5,11!', label = 'attnSel']
d3 [pos = '6.5,11!', label = 'attnDiv']
e3 [pos = '8,11!', label = 'attnOpp']
f3 [pos = '9.5,11!', label = 'sdqHyp']
ag1 [pos = '9,9!', label = 'f8Age']
ag2 [pos = '9,8!', label = 'f9Age']
ag3 [pos = '9,7!', label = 'f10Age']
ag1->d2
ag1->e2
ag1->a3
ag1->c3
ag1->d3
ag1->e3
ag2->d
ag2->e
ag2->c
ag2->b
ag2->i
ag2->a
ag2->k
ag2->a2
ag2->b2
ag2->c2
ag3->b3
f->a
f->b 
g->c
g->d
g->e
h->a 
h->b
h->c
h->d
h->e
h->i
h->j
h->k
h->a2 
h->b2
h->c2
h->d2
h->e2
h->a3 
h->b3
h->c3
h->d3
h->e3
h->f3
l->j
l->k
m->a2 
m->b2
m->c2
m->d2
m->e2
n->a3 
n->b3
n->c3
n->d3
n->e3
n->f3
}
")
#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-a-fit}
m_fmm_a <- lapply(2, function(k) {
  
  # Update model spec 1: overall model estimates (variances and covariances)
  body<-update(m_fmm_base,
              MODEL = as.formula(sprintf("~ . + '%s %s'", factor_vars, factor_covars)))
  
  # Create class-level specifications (factor variances and covariances)
  class_spec <- paste0("%c#1%", factor_vars, factor_covars, ind_means)
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "%", factor_vars, factor_covars, ind_means)
  }
  
  # ...Update model spec 2: class estimates
  body <- update(body,
     TITLE = as.formula(sprintf("~ 'FMM Model A: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))

  # Run model
  mplusModeler(body, sprintf("./mplus_models/compprof/fmm/cp_fmm_a_%dclass.dat", k), run = TRUE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-a-output}
# Read in output
fmm_a_out <- readModels(target = "./mplus_models/compprof/fmm", filefilter = "cp_fmm_a")

# Check warnings
for (model in 1:length(fmm_a_out)){
  print(fmm_a_out[[model]]$input$title)
  print(fmm_a_out[[model]]$warnings)
}

# Print table 
fmm_a_summary <- fmm_enum_table(output = fmm_a_out)
fmm_a_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_a_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 
**b) Information heuristics (diminishing gains from elbow plots):** 
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):**

Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-a-candidates}
# Extract participant level data
fmm_a_rerun <- mm_extract_data(orig_mods = m_fmm_a, orig_output = fmm_a_out,
                               candidate_mods = 3:4,    # change to candidate models
                               filepath = "./mplus_models/compprof/fmm", analysis_id = "cp",
                               rerun = FALSE, optseed = TRUE,
                               one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_a_rerun)

# Plot class means (use select_model if not all models ran correctly)
### Note - plot saves to output/figures/ >> open and inspect separately for proper viewing
plotMixtures_compProf(fmm_a_rerun, select_model = 2)

# Inspect transitions - to edit
# extract_classes(fmm_a_rerun, select_model = 3:4, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-a-selected}
# fmm_a_final_nclass <- 3           # change to selected model
# fmm_a_final_m <- fmm_a_rerun[1]   # change to selected model
```


### FMM Model B

Tests different N-Class, 2 factor FMM models. Class varying item means, class varying factor loadings, class varying factor covariance matrix, factor means fixed at zero (for identifiability)

```{r fmm-b-diag}
grViz("
digraph SEM {
graph [layout = neato,
       overlap = true,
       outputorder = edgesfirst]
node [shape = rectangle,fontsize=16]
a [pos = '-3.5,3!', label = 'woldcomp']
b [pos = '-2,3!', label = 'naracomp']
c [pos = '-0.5,3!', label = 'naraAcc']
d [pos = '1,3!', label = 'wordAcc']
e [pos = '2.5,3!', label = 'nonwAcc']
f [pos = '-2.75,7!', label = 'comp', shape = ellipse,fontsize=16]
g [pos = '1,7!', label = 'acc', shape = ellipse,fontsize=16]
h [pos = '-1,8!', label = 'C', shape = ellipse,fontsize=20]
i [pos = '-5,3!', label = 'naraRate']
j [pos = '5,3!', label = 'wiscVcb']
k [pos = '6.5,3!', label = 'woldVcb']
l [pos = '5.5,7!', label = 'vocab', shape = ellipse,fontsize=16]
m [pos = '-4.5,9!', label = 'perfig', shape = ellipse,fontsize=16]
a2 [pos = '-6,11!', label = 'wiscPcmp']
b2 [pos = '-4.5,11!', label = 'wiscCode']
c2 [pos = '-3,11!', label = 'wiscParr']
d2 [pos = '-1.5,11!', label = 'wiscBloc']
e2 [pos = '0,11!', label = 'wiscObja']
n [pos = '6.5,9!', label = 'execfun', shape = ellipse,fontsize=16]
a3 [pos = '2,11!', label = 'wiscBwsp']
b3 [pos = '3.5,11!', label = 'cntSpan']
c3 [pos = '5,11!', label = 'attnSel']
d3 [pos = '6.5,11!', label = 'attnDiv']
e3 [pos = '8,11!', label = 'attnOpp']
f3 [pos = '9.5,11!', label = 'sdqHyp']
ag1 [pos = '0,13!', label = 'f8Age']
ag2 [pos = '-8,8!', label = 'f9Age']
ag3 [pos = '3.5,13!', label = 'f10Age']
ag1->d2
ag1->e2
ag1->a3
ag1->c3
ag1->d3
ag1->e3
ag2->d
ag2->e
ag2->c
ag2->b
ag2->i
ag2->a
ag2->k
ag2->a2
ag2->b2
ag2->c2
ag3->b3
f->a
f->b 
g->c
g->d
g->e
h->a 
h->b
h->c
h->d
h->e
h->i
h->j
h->k
h->a2 
h->b2
h->c2
h->d2
h->e2
h->a3 
h->b3
h->c3
h->d3
h->e3
h->f3
l->j
l->k
m->a2 
m->b2
m->c2
m->d2
m->e2
n->a3 
n->b3
n->c3
n->d3
n->e3
n->f3
node [shape = circle,
        fixedsize = true,
        width = 0.1,
        color = white,
        fontcolor = white]
ah [pos = '-3.2,5!']
bh [pos = '-2.5,5.2!']
ch [pos = '0.4,5.2!']
dh [pos = '1,5.4!']
eh [pos = '1.72,5!']
jh [pos = '5.3,5!']
kh [pos = '6,5!']
a2h [pos = '-5.3,10!']
b2h [pos = '-4.5,10!']
c2h [pos = '-3.8,10!']
d2h [pos = '-3.1,10!']
e2h [pos = '-2.5,10!']
a3h [pos = '4,10.2!']
b3h [pos = '4.8,10.2!']
c3h [pos = '5.75,10!']
d3h [pos = '6.5,10!']
e3h [pos = '7.25,10!']
f3h [pos = '8,10!']
h->ah [style = dashed]
h->bh [style = dashed]
h->ch [style = dashed]
h->dh [style = dashed]
h->eh [style = dashed]
h->jh [style = dashed]
h->kh [style = dashed]
h->a2h [style = dashed]
h->b2h [style = dashed]
h->c2h [style = dashed]
h->d2h [style = dashed]
h->e2h [style = dashed]
h->a3h [style = dashed] 
h->b3h [style = dashed]
h->c3h [style = dashed]
h->d3h [style = dashed]
h->e3h [style = dashed]
h->f3h [style = dashed]
}
")
#d->c [dir = both]
```

Steps 1-3) Fit series of increasing *k*-class models.

```{r fmm-b-fit}
m_fmm_b <- lapply(2:6, function(k) {
  
  # Create class-level specifications (factor loadings, factor variance and covariance)
  class_spec <- paste0("%c#1%", factor_spec_class, factor_vars, factor_covars, ind_means)
  for (i in 2:k){
    class_spec <- paste0(class_spec, "\n %c#", i, "%", factor_spec_class, factor_vars, factor_covars, ind_means)
  }
  
  # Update model
  body <- update(m_fmm_base,
     TITLE = as.formula(sprintf("~ 'FMM Model B: %d classes;'", k)),
     VARIABLE = as.formula(sprintf("~ 'classes = c(%d);'", k)),
     MODEL = as.formula(sprintf("~ . + '%s'", class_spec)))
 
  # Run model
   mplusModeler(body, sprintf("./mplus_models/compprof/fmm/cp_fmm_b_%dclass.dat", k), run = TRUE)
 })
```

Steps 4-5) Extract fit indices, and use to select smaller subset of candidate models.

```{r fmm-b-output}
# Read in output
fmm_b_out <- readModels(target = "./mplus_models/compprof/fmm", filefilter = "cp_fmm_b")

# Check warnings
for (model in 1:length(fmm_b_out)){
  print(fmm_b_out[[model]]$input$title)
  print(fmm_b_out[[model]]$warnings)
}

# Print table 
fmm_b_summary <- fmm_enum_table(output = fmm_b_out)
fmm_b_summary

# Elbow plots for information criteria
fmm_enum_elbow(fmm_b_summary, benchmark_stats = m_fmm_benchmark)
```

Best model for:
**a) Absolute fit (fewest classes with better LL than benchmark):** 
**b) Information heuristics (diminishing gains from elbow plots):** 
**c) Adjusted LRTs (fewest classes not sig improved by additional classes):** 


Step 6) View classification diagnostics for candidate models. Can also inspect how the classes correspond across models. 

```{r fmm-b-candidates}
# Extract participant level data
fmm_b_rerun <- mm_extract_data(orig_mods = m_fmm_b, orig_output = fmm_b_out, 
                               candidate_mods = 2:3,                           # change models to best candidates
                               filepath = "mplus_models/simpview/fmm",
                               rerun = TRUE, optseed = TRUE,          
                               one_fit = FALSE)

# Compute classification diagnostics
class_diag(fmm_b_rerun)

# Plot class means
plotMixtures_simpView(fmm_b_rerun)

# Inspect transitions 
extract_classes(fmm_b_rerun, type = "fmm")
```

Comments:
**Classification diagnostics:**
**Interpretability:** 

Step 7) Select final model in class enumeration process, for model specification A. 
```{r fmm-b-selected} 
# fmm_b_final_nclass <- 3           # change to selected model
# fmm_b_final_m <- fmm_b_rerun[1]   # change to selected model
```


### All FMM models: Summary output & final selection

Use the 2 best candidate models identified above to recalculate the approximate correct model probability.

```{r final-candidates}
# Select best models
best_fits <- c(fmm_a_final_m, fmm_b_final_m)

# Compare outputs 
best_summaries <- fmm_enum_table(best_fits) %>% 
  select(-c(VLMR_p, LMR_p, bLRT_p))

# Compute classification diagnostics
class_diag(best_fits)

# Plot class means
plotMixtures_simpView(best_fits)

# Inspect transitions 
extract_classes(best_fits, type = "fmm")
```

```{r fmm-all-table}
# Combine all summary tables
fmm_all_summaries <- rbind(fmm_a_summary, fmm_b_summary) 

# Extract number of classes modelled in class enumeration process
k_classes_modelled <- max(fmm_all_summaries$Classes) -1

# Specify table row for selected models for each spec
a_row <- which(grepl(fmm_a_final_nclass, fmm_a_summary$Classes))
b_row <- k_classes_modelled + which(grepl(fmm_b_final_nclass, fmm_b_summary$Classes))

# Format table, highlight class model of best fit in each specification
table_all <- fmm_all_summaries %>% 
  mutate(Specification = "") %>% 
  replace(is.na(.), "-") %>% 
  kbl(align = c("l", "c", "r", "c", "r", "r","r","r","r","r","r","r")) %>% 
  kable_classic(html_font = "Cambria") %>% 
  pack_rows(index = c("Model A" = k_classes_modelled, "Model B" = k_classes_modelled)) %>% 
  row_spec(c(a_row, b_row), bold = T) 
table_all

# Save table as pdf for later viewing
# save_kable(table_all, file = "../output/tables/CompProf_fmm_all_modelfit.pdf")
```

```{r fmm-all-elbow}
# Grouped elbow plots
fmm_all_summaries %>%
    mutate(model_spec = substr(Specification, 11, 12)) %>% 
    select(model_spec, Classes, LL, AIC,  BIC, aBIC) %>%
    pivot_longer(LL:aBIC, names_to = "statistic", values_to = "value") %>%
    mutate(statistic_relevel = factor(statistic, levels = c("LL", "AIC", "BIC", "aBIC"))) %>% 
    ggplot(aes(x = as.factor(Classes), y = value)) +
    geom_point(aes(shape = model_spec)) +
    geom_line(aes(group = model_spec, linetype = model_spec)) +
    xlab("n classes") +
    theme_bw() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.y = element_blank()) +
    geom_hline(data = m_fmm_benchmark, aes(yintercept = benchmark), linetype = "dashed", colour = "red") +
    facet_wrap(statistic_relevel ~., scales = "free") + 
    labs(shape = "Model spec:", linetype = "Model spec:")

# save out for easier viewing
ggsave("../output/figures/CompProf_fmm_all_indices.tiff", dpi = 600, width = 7, height = 4, units = "in")
```

# Final selected model

The final model will be re-run using bootstrapping to indicate robustness. 

```{r final-model}

```