---
title: "LPA with simulated reading data"
output: 
  html_document:
    toc: true
    toc_float: true
---

This script is a first attempt at using the tidyLPA package to perform a latent profile analysis. 
It uses simulated data, designed around the variables available in ALSPAC for the first analysis (Simple View).  

Package vignette: [https://data-edu.github.io/tidyLPA/articles/Introduction_to_tidyLPA.html](https://data-edu.github.io/tidyLPA/articles/Introduction_to_tidyLPA.html).See also [this tutorial](https://rstudio-pubs-static.s3.amazonaws.com/553733_4d23ff5746ec4c8584969ce0768d6db5.html) for some further comments. 

```{r libraries, message = FALSE, warning = FALSE}
library(SIN)
library(MASS)
library(psych)
library(naniar)
library(tidyverse)
library(tidyLPA)
library(GGally)
library(MplusAutomation)
library(texreg)
```


```{r set-up}
options(scipen = 999)
set.seed(20201105)
```

# Simulate data

Create dataset similar to one that we will use - three reading accuracy measures, a reading comprehension measure and listening comprehension.  

### Specify variables and relationships

For now, have just used standard score estimates for each task, and made up the correlations. 

```{r measures}

#CLASS 1

################# MEASURES ###################

# NARA - comprehension
nara_comp_m1 <- 105
nara_comp_sd1 <- 5
  
# NARA - accuracy
nara_acc_m1 <- 105
nara_acc_sd1 <- 5

# Word/nonword reading
word_acc_m1 <- 105
word_acc_sd1 <- 5
nonword_acc_m1 <- 105
nonword_acc_sd1 <-5

# WOLD listening
wold_comp_m1 <- 105
wold_comp_sd1 <- 5

#CLASS 2

################# MEASURES ###################

# NARA - comprehension
nara_comp_m2 <- 80
nara_comp_sd2 <- 7
  
# NARA - accuracy
nara_acc_m2 <- 80
nara_acc_sd2 <- 7

# Word/nonword reading
word_acc_m2 <- 80
word_acc_sd2 <- 7
nonword_acc_m2 <- 80
nonword_acc_sd2 <-7

# WOLD listening
wold_comp_m2 <- 80
wold_comp_sd2 <- 7

#CLASS 3

################# MEASURES ###################

# NARA - comprehension
nara_comp_m3 <- 90
nara_comp_sd3 <- 10
  
# NARA - accuracy
nara_acc_m3 <- 90
nara_acc_sd3 <- 10

# Word/nonword reading
word_acc_m3 <- 90
word_acc_sd3 <- 10
nonword_acc_m3 <- 90
nonword_acc_sd3 <-10

# WOLD listening
wold_comp_m3 <- 90
wold_comp_sd3 <- 10


################# CORRELATIONS ###################

#assumption is that we have same correlation among measures for each class

nara_comp_acc <- 0.5
nara_comp_word <- 0.4
nara_comp_nonword <- 0.4
nara_comp_wold <- 0.6
nara_acc_word <- 0.6
nara_acc_nonword <- 0.5
nara_acc_wold <- 0.2
word_acc_nonword <- 0.7
word_acc_wold <- 0.2
nonword_acc_wold <- 0.2
```

*If using raw scores, how can we account for age differences? Regress out of each raw score?*

### Simulate dataset

Compute covariance matrix based on the above estimates, and use to simulate specified number of observations.

```{r simulate-data}
################# COVARIANCES ###################

# List names in order
test_names <- c("nara_comp", "nara_acc", "word_acc", "nonword_acc", "wold_comp")

# List SDs in order above
stddev1 <- c(nara_comp_sd1, nara_acc_sd1, word_acc_sd1, nonword_acc_sd1, wold_comp_sd1)
stddev2 <- c(nara_comp_sd2, nara_acc_sd2, word_acc_sd2, nonword_acc_sd2, wold_comp_sd2)
stddev3 <- c(nara_comp_sd3, nara_acc_sd3, word_acc_sd3, nonword_acc_sd3, wold_comp_sd3)

# Create correlation matrix using above estimates
corr <- matrix(c(1, nara_comp_acc, nara_comp_word, nara_comp_nonword, nara_comp_wold,
                 nara_comp_acc, 1, nara_acc_word, nara_acc_nonword, nara_acc_wold,
                 nara_comp_word, nara_acc_word, 1, word_acc_nonword, word_acc_wold,
                 nara_comp_nonword, nara_acc_nonword, word_acc_nonword, 1, nonword_acc_wold,
                 nara_comp_wold, nara_acc_wold, word_acc_wold, nonword_acc_wold, 1),
               byrow = TRUE, nrow = 5, 
               dimnames = list(test_names, test_names))

# Compute covariance matrix
covar1 <- sdcor2cov(stddev1, corr)
covar2 <- sdcor2cov(stddev2, corr)
covar3 <- sdcor2cov(stddev3, corr)

################# SIMULATE DATA ###################

# List means in order above
means1 <- c(nara_comp_m1, nara_acc_m1, word_acc_m1, nonword_acc_m1, wold_comp_m1)
means2 <- c(nara_comp_m2, nara_acc_m2, word_acc_m2, nonword_acc_m2, wold_comp_m2)
means3 <- c(nara_comp_m3, nara_acc_m3, word_acc_m3, nonword_acc_m3, wold_comp_m3)

# Number of observations
n_ppts <- 1000

#latent profile probabilities.
class_probs<-c(0.6,0.2,0.2)

# generate mixing profile indicator based on profile probabilities
k<-sample(1:3,n_ppts,class_probs,replace=TRUE)

# Set up empty holding dataframe
sim_dat <-data.frame(nara_comp=numeric(), nara_acc=numeric(), word_acc=numeric(), nonword_acc=numeric(), wold_comp=numeric())

#sample from the three multivariate normal distributions in the correct proportions according to profile probabilities.
for(i in 1:n_ppts){
sim_dat[i,]<-switch(k[i],mvrnorm(n = 1, mu = means1, Sigma = covar1), mvrnorm(n = 1, mu = means2, Sigma = covar2), mvrnorm(n = 1, mu = means3, Sigma = covar3))
}
sim_dat <- as.data.frame(cbind(sim_dat,as.factor(k)))

#create a dummy id (change as needed)
sim_dat$id<-paste0("ALSPAC",sprintf('%0.4d', 1:n_ppts))

names(sim_dat)<-c("naraComp", "naraAcc", "wordAcc", "nonwordAcc", "woldComp","k","id")
```

### Missing data

PT: There are different ways to do this and we need to decide which is most realistic for our data. We can remove a percentage of the data completely at random, so random observations are missing, or potentially more likely is that certain individuals will have multiple observations missing, i.e. if there is a missing observation for nara_comp, then I guess its more likely that nara_acc will also be missing too? I've implemented the first option here, but you could add a second step to search for NAs in a row and add extra NAs to that row.

https://stackoverflow.com/questions/50528719/simulate-data-and-randomly-add-missing-values-to-dataframe

**Missing data expectations for this analysis:**
* nara_comp should have no missing data, as inclusion in this/subsequent projects relies on having a comprehension assessment (*unless this should be addressed differently? not quite sure where sample stops otherwise?*)
* nara_acc should have very little missing data - collected at same time as nara_comp, but will be very small proportion due to error
* word_acc & nonword_acc will also have only a very small proportion - collected in same assessment session as nara. Possibly more likely that if word_acc missing then nonword_acc also missing (?), but numbers very small. 
* wold_comp - more likely to have missing data; collected at different clinic session one year earlier 

EJ: For this analysis, it doesn't seem as if there are specific contingencies in missingness (unless we need to incorporate missing nara_comp somehow?), but some variability in likely proportions due to whether the data were collected in same/different clinic visits. I have updated the code to incorporate different proportions.

```{r missing-data}
# specify variables collected in same session, low proportion missingness
same_na_cols <- c("naraAcc", "wordAcc", "nonwordAcc")
same_na_prop <- 0.01

# specify variables collected in separate session, higher proportion missingness
sep_na_cols <- "woldComp"
sep_na_prop <- 0.05

# Create dataframe with NAs
sim_dat_NA <- sim_dat %>% 
  pivot_longer(cols = -c(id,k),names_to = "var", values_to = "value") %>%    # pivot data to long format
  mutate(r = runif(nrow(.)),                                            # simulate a random number (r) from 0 to 1 for each row
         value = ifelse(var %in% same_na_cols & r <= same_na_prop, NA,  # for same session vars, update to NA if r < threshold
                        ifelse(var %in% sep_na_cols & r <= sep_na_prop, NA, value))) %>%  # for separate session vars, update to NA is r < threshold, else same value
  dplyr::select(-r) %>%                                                        # remove random number
  pivot_wider(names_from = var, values_from = value)                    # pivot back to original format
```


# Data check

Inspect properties of the variables. 

```{r summarise-vars}
# Quick summary statistics
summary(sim_dat_NA)

#You can get more comprehensive summary statistics using the psych package
describe(sim_dat_NA)


# Check histograms/correlations
pairs.panels(sim_dat_NA)



sim_dat_NA %>% dplyr::select(-id) %>% ggpairs(mapping = aes(color = k))
```

### Missing data

Inspect missingness in the data.

```{r missingness}
vis_miss(sim_dat_NA)
```
(Other tools for visualising relationships in missingness: https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)

*...decide what to do with missing data for this analysis.* 


```{r compare-mods, }
sim_dat_NA %>% dplyr::select(-c(id,k)) %>%
  estimate_profiles(1:9, package = "MplusAutomation") %>% 
  compare_solutions(statistics = c("AIC", "BIC", "ICL","SABIC", "Entropy", "BLRT_val", "BLRT_p"))

sim_dat_NA %>% dplyr::select(-c(id,k)) %>%
estimate_profiles(9, package = "MplusAutomation") %>% plot_profiles() 

```

# Fitting simple LPA model in Mplus (manually specifying the mplus model)

```{r mplus-prep}


#prepare data, converting R data.frame to Mplus readable file.
sim_dat_NA2<-sim_dat_NA

names(sim_dat_NA2)<-c("k", "id", "naraComp", "naraAcc", "wordAcc", "nonwordAcc", "woldComp")

#prepare the model script file. This can be done using a .txt file then using 


pathmodel3 <- mplusObject(
TITLE= "LCA with continuous latent class indicators;",
VARIABLE = "CLASSES = c (3);",
ANALYSIS = "
TYPE = MIXTURE; 
STARTS = 0;",
MODEL = "
%OVERALL% 
%c#1% 
[naraComp-woldComp]; 
%c#2% 
[naraComp-woldComp];
%c#3% 
[naraComp-woldComp];",
OUTPUT = "TECH1 TECH8;",
usevariables = c("naraComp", "naraAcc", "wordAcc", "nonwordAcc", "woldComp"),
rdata = sim_dat_NA2[,!names(sim_dat_NA2) %in% c("id","k")])

pathmodel2 <- mplusObject(
TITLE= "LCA with continuous latent class indicators (2);",
VARIABLE = "CLASSES = c (2);",
ANALYSIS = "
TYPE = MIXTURE; 
STARTS = 0;",
MODEL = "
%OVERALL% 
%c#1% 
[naraComp-woldComp]; 
%c#2% 
[naraComp-woldComp];",
OUTPUT = "TECH1 TECH8;",
usevariables = c("naraComp", "naraAcc", "wordAcc", "nonwordAcc", "woldComp"),
rdata = sim_dat_NA2[,!names(sim_dat_NA2) %in% c("id","k")])

fit2 <- mplusModeler(pathmodel2, modelout = "model_LPA2.inp", run = 1L,check=TRUE,varwarnings=TRUE)
fit3 <- mplusModeler(pathmodel3, modelout = "model_LPA3.inp", run = 1L,check=TRUE,varwarnings=TRUE)


screenreg(fit2, single.row=TRUE)
screenreg(fit3, single.row=TRUE)

```


```{r multi_template}

m.cfa <- mplusObject(
    TITLE = "Confirmatory Factor Analysis",
    ANALYSIS = "estimator = mlr;",
    MODEL = "factor BY naraComp-woldComp;",
    OUTPUT = "TECH1; TECH8;",
    PLOT = "TYPE = PLOT3;",
    usevariables = colnames(sim_dat_NA2[,!names(sim_dat_NA2) %in% c("id","k")]),
    rdata = sim_dat_NA2[,!names(sim_dat_NA2) %in% c("id","k")])

m.cfa.fit <- mplusModeler(m.cfa, "cfa_example.dat", run = TRUE)

m.lca <- lapply(2:5, function(k) {
   body <- update(m.cfa,
     TITLE = as.formula(sprintf("~ 'class-%d;'", k)),
     VARIABLE = as.formula(sprintf("~ . + 'classes = c(%d);'", k)),
     ANALYSIS = ~ . + "type = mixture; starts = 250 25;",
     MODEL = ~ "%OVERALL%",
     OUTPUT = ~ . + "TECH14;")

   mplusModeler(body, sprintf("lpa_%d_example.dat", k), run = TRUE)
 })

LPAModels <- readModels("/Volumes/PSYHOME/PSYRES/pthompson/DVMB/ESRC_EJ_WP1/mplus_test_scripts")

```

